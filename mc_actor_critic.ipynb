{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30627bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, os\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from math import cos\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f857fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.linear1 = nn.Linear(17, 8)\n",
    "        self.linear3 = nn.Linear(8, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        output = F.relu((self.linear1(state)))\n",
    "        output = self.linear3(output)\n",
    "        distribution = F.softmax(output, dim=1)\n",
    "        return distribution\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.linear1 = nn.Linear(17, 8)\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        output = F.relu((self.linear1(state)))\n",
    "        # output = F.relu(self.linear2(output))\n",
    "        value = self.linear3(output)\n",
    "        return value\n",
    "\n",
    "def pick_action(actor, state):\n",
    "    # state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    action_probs = actor(state)\n",
    "    \n",
    "    dist = Categorical(action_probs)\n",
    "    action = dist.sample()\n",
    "\n",
    "    return action.item(), dist.log_prob(action)\n",
    "\n",
    "def min_max_scale(state):\n",
    "    new_state = np.zeros(2)\n",
    "    new_state[0] = (state[0]+1.2)/(1.8)\n",
    "    new_state[1] = (state[1]+0.07)/(0.14)\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def fourier_basis(curr_state, M=8):\n",
    "    x = curr_state[0]\n",
    "    v = curr_state[1]\n",
    "    v_list = []\n",
    "    x_list = []\n",
    "    for i in range(M+1):\n",
    "        state_func = cos\n",
    "        x_list.append(state_func(i*x))\n",
    "        if i > 0:\n",
    "            v_list.append(state_func(i*np.pi*v))\n",
    "    phi = x_list + v_list\n",
    "    phi = np.array(phi) #.reshape(1,-1)\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce1e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the count 10000 for episode 0\n",
      "This is the count 10000 for episode 1\n",
      "This is the count 10000 for episode 2\n",
      "Num episodes 3, num actions 8206 True\n",
      "This is the count 8206 for episode 3\n",
      "Num episodes 4, num actions 2936 True\n",
      "This is the count 2936 for episode 4\n",
      "Num episodes 5, num actions 5582 True\n",
      "This is the count 5582 for episode 5\n",
      "Num episodes 6, num actions 7043 True\n",
      "This is the count 7043 for episode 6\n",
      "This is the count 10000 for episode 7\n",
      "Num episodes 8, num actions 3813 True\n",
      "This is the count 3813 for episode 8\n",
      "Num episodes 9, num actions 3507 True\n",
      "This is the count 3507 for episode 9\n",
      "Num episodes 10, num actions 3721 True\n",
      "This is the count 3721 for episode 10\n",
      "Num episodes 11, num actions 3312 True\n",
      "This is the count 3312 for episode 11\n",
      "Num episodes 12, num actions 7062 True\n",
      "This is the count 7062 for episode 12\n",
      "Num episodes 13, num actions 6398 True\n",
      "This is the count 6398 for episode 13\n",
      "Num episodes 14, num actions 6315 True\n",
      "This is the count 6315 for episode 14\n",
      "Num episodes 15, num actions 1757 True\n",
      "This is the count 1757 for episode 15\n",
      "Num episodes 16, num actions 4585 True\n",
      "This is the count 4585 for episode 16\n",
      "Num episodes 17, num actions 6194 True\n",
      "This is the count 6194 for episode 17\n",
      "Num episodes 18, num actions 7439 True\n",
      "This is the count 7439 for episode 18\n",
      "Num episodes 19, num actions 2515 True\n",
      "This is the count 2515 for episode 19\n",
      "Num episodes 20, num actions 5050 True\n",
      "This is the count 5050 for episode 20\n",
      "Num episodes 21, num actions 4419 True\n",
      "This is the count 4419 for episode 21\n",
      "Num episodes 22, num actions 7977 True\n",
      "This is the count 7977 for episode 22\n",
      "Num episodes 23, num actions 3876 True\n",
      "This is the count 3876 for episode 23\n",
      "Num episodes 24, num actions 2927 True\n",
      "This is the count 2927 for episode 24\n",
      "Num episodes 25, num actions 5791 True\n",
      "This is the count 5791 for episode 25\n",
      "Num episodes 26, num actions 1831 True\n",
      "This is the count 1831 for episode 26\n",
      "Num episodes 27, num actions 1873 True\n",
      "This is the count 1873 for episode 27\n",
      "Num episodes 28, num actions 8982 True\n",
      "This is the count 8982 for episode 28\n",
      "Num episodes 29, num actions 5068 True\n",
      "This is the count 5068 for episode 29\n",
      "Num episodes 30, num actions 5407 True\n",
      "This is the count 5407 for episode 30\n",
      "Num episodes 31, num actions 3946 True\n",
      "This is the count 3946 for episode 31\n",
      "Num episodes 32, num actions 2706 True\n",
      "This is the count 2706 for episode 32\n",
      "Num episodes 33, num actions 6576 True\n",
      "This is the count 6576 for episode 33\n",
      "Num episodes 34, num actions 1757 True\n",
      "This is the count 1757 for episode 34\n",
      "Num episodes 35, num actions 4798 True\n",
      "This is the count 4798 for episode 35\n",
      "Num episodes 36, num actions 7541 True\n",
      "This is the count 7541 for episode 36\n",
      "Num episodes 37, num actions 7809 True\n",
      "This is the count 7809 for episode 37\n",
      "Num episodes 38, num actions 5802 True\n",
      "This is the count 5802 for episode 38\n",
      "Num episodes 39, num actions 3599 True\n",
      "This is the count 3599 for episode 39\n",
      "Num episodes 40, num actions 7703 True\n",
      "This is the count 7703 for episode 40\n",
      "Num episodes 41, num actions 2313 True\n",
      "This is the count 2313 for episode 41\n",
      "Num episodes 42, num actions 4369 True\n",
      "This is the count 4369 for episode 42\n",
      "Num episodes 43, num actions 7631 True\n",
      "This is the count 7631 for episode 43\n",
      "Num episodes 44, num actions 3823 True\n",
      "This is the count 3823 for episode 44\n",
      "This is the count 10000 for episode 45\n",
      "Num episodes 46, num actions 2071 True\n",
      "This is the count 2071 for episode 46\n",
      "Num episodes 47, num actions 5226 True\n",
      "This is the count 5226 for episode 47\n",
      "Num episodes 48, num actions 4749 True\n",
      "This is the count 4749 for episode 48\n",
      "Num episodes 49, num actions 4280 True\n",
      "This is the count 4280 for episode 49\n",
      "Num episodes 50, num actions 2770 True\n",
      "This is the count 2770 for episode 50\n",
      "Num episodes 51, num actions 3410 True\n",
      "This is the count 3410 for episode 51\n",
      "Num episodes 52, num actions 4728 True\n",
      "This is the count 4728 for episode 52\n",
      "Num episodes 53, num actions 5156 True\n",
      "This is the count 5156 for episode 53\n",
      "Num episodes 54, num actions 5329 True\n",
      "This is the count 5329 for episode 54\n",
      "Num episodes 55, num actions 5334 True\n",
      "This is the count 5334 for episode 55\n",
      "This is the count 10000 for episode 56\n",
      "Num episodes 57, num actions 3155 True\n",
      "This is the count 3155 for episode 57\n",
      "Num episodes 58, num actions 9417 True\n",
      "This is the count 9417 for episode 58\n",
      "Num episodes 59, num actions 1653 True\n",
      "This is the count 1653 for episode 59\n",
      "This is the count 10000 for episode 60\n",
      "This is the count 10000 for episode 61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3160\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3160\u001b[0m     \u001b[39mreturn\u001b[39;00m a\u001b[39m.\u001b[39;49mndim\n\u001b[1;32m   3161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'ndim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m#Pick action\u001b[39;00m\n\u001b[1;32m     45\u001b[0m action, log_prob \u001b[39m=\u001b[39m pick_action(actor, state\u001b[39m=\u001b[39mstate_tensor)\n\u001b[0;32m---> 46\u001b[0m state_prime, reward, isTerminal, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     49\u001b[0m phi_next \u001b[39m=\u001b[39m fourier_basis(min_max_scale(state_prime))\n\u001b[1;32m     50\u001b[0m state_prime_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(phi_next)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/wrappers/time_limit.py:18\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     15\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/classic_control/mountain_car.py:89\u001b[0m, in \u001b[0;36mMountainCarEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     87\u001b[0m position, velocity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n\u001b[1;32m     88\u001b[0m velocity \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (action \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforce \u001b[39m+\u001b[39m math\u001b[39m.\u001b[39mcos(\u001b[39m3\u001b[39m \u001b[39m*\u001b[39m position) \u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgravity)\n\u001b[0;32m---> 89\u001b[0m velocity \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mclip(velocity, \u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_speed, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_speed)\n\u001b[1;32m     90\u001b[0m position \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m velocity\n\u001b[1;32m     91\u001b[0m position \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(position, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_position, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_position)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2115\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[1;32m   2047\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclip\u001b[39m(a, a_min, a_max, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2048\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m \u001b[39m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2113\u001b[0m \n\u001b[1;32m   2114\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2115\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mclip\u001b[39;49m\u001b[39m'\u001b[39;49m, a_min, a_max, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:134\u001b[0m, in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _clip_dep_is_byte_swapped(a) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _clip_dep_is_byte_swapped(out):\n\u001b[1;32m    133\u001b[0m     using_deprecated_nan \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mif\u001b[39;00m _clip_dep_is_scalar_nan(\u001b[39mmin\u001b[39;49m):\n\u001b[1;32m    135\u001b[0m         \u001b[39mmin\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    136\u001b[0m         using_deprecated_nan \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:94\u001b[0m, in \u001b[0;36m_clip_dep_is_scalar_nan\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_clip_dep_is_scalar_nan\u001b[39m(a):\n\u001b[1;32m     92\u001b[0m     \u001b[39m# guarded to protect circular imports\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfromnumeric\u001b[39;00m \u001b[39mimport\u001b[39;00m ndim\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mif\u001b[39;00m ndim(a) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     95\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3160\u001b[0m, in \u001b[0;36mndim\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3130\u001b[0m \u001b[39mReturn the number of dimensions of an array.\u001b[39;00m\n\u001b[1;32m   3131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3157\u001b[0m \n\u001b[1;32m   3158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3160\u001b[0m     \u001b[39mreturn\u001b[39;00m a\u001b[39m.\u001b[39;49mndim\n\u001b[1;32m   3161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   3162\u001b[0m     \u001b[39mreturn\u001b[39;00m asarray(a)\u001b[39m.\u001b[39mndim\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gamma = 0.90\n",
    "num_episodes = 100\n",
    "num_steps = 10000\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "# env = gym.envs.make(\"MountainCarContinuous-v0\")\n",
    "\n",
    "# env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "count_episode = range(1,num_episodes+1)\n",
    "count_ca = []\n",
    "count_tca = []\n",
    "decay_rate = 10\n",
    "\n",
    "\n",
    "for k in range(1):\n",
    "    actor = Actor(state_size=state_size, action_size=action_size)\n",
    "    critic = Critic(state_size)\n",
    "\n",
    "    \n",
    "    count_actions = []\n",
    "    total_count_actions = []\n",
    "    total_a = 0\n",
    "    actor_optim = optim.SGD(actor.parameters(),lr=1)\n",
    "    critic_optim = optim.SGD(critic.parameters(), lr=1)\n",
    "    decayRate = 0.1\n",
    "    actor_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=actor_optim, gamma=decayRate)\n",
    "    critic_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=actor_optim, gamma=decayRate)\n",
    "    for episode in range(num_episodes):\n",
    "        \n",
    "        state = env.reset()\n",
    "        isTerminal = False\n",
    "        score = 0\n",
    "        count_a = 0\n",
    "        \n",
    "        # while isTerminal != True:\n",
    "        for i in range(num_steps): \n",
    "            count_a += 1\n",
    "            \n",
    "            phi_curr = fourier_basis(min_max_scale(state))    \n",
    "            state_tensor = torch.from_numpy(phi_curr).float().unsqueeze(0)\n",
    "            v_curr = critic(state_tensor)\n",
    "            #Pick action\n",
    "            action, log_prob = pick_action(actor, state=state_tensor)\n",
    "            state_prime, reward, isTerminal, info = env.step(action)\n",
    "            \n",
    "\n",
    "            phi_next = fourier_basis(min_max_scale(state_prime))\n",
    "            state_prime_tensor = torch.from_numpy(phi_next).float().unsqueeze(0)\n",
    "            v_next = critic(state_prime_tensor)\n",
    "\n",
    "            if state_prime[0] >= 0.5:\n",
    "                print(f'Num episodes {episode}, num actions {count_a} {isTerminal}')\n",
    "                v_next = torch.tensor([0]).float().unsqueeze(0)\n",
    "            # if isTerminal:\n",
    "            #     print(f'Num episodes {episode}, num actions {i} {isTerminal}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # if isTerminal:\n",
    "            #     v_next = torch.tensor([0]).float().unsqueeze(0)\n",
    "\n",
    "            # if state_prime[0] >= 0.5:\n",
    "            #     v_next = torch.tensor([0]).float().unsqueeze(0)\n",
    "            #     reward += 1000\n",
    "            td_target = reward + gamma * v_next\n",
    "            td_error = reward + gamma*v_next.item()-v_curr.item()\n",
    "            critic_loss = F.mse_loss(td_target,v_curgit pullr)\n",
    "            actor_loss = -log_prob * td_error\n",
    "            \n",
    "            actor_optim.zero_grad()\n",
    "            actor_loss.backward(retain_graph=True)\n",
    "            \n",
    "            if state_prime[0] >= 0.5:\n",
    "                actor_optim.step()\n",
    "                actor_lr_scheduler.step()\n",
    "            \n",
    "            # print(critic_loss)\n",
    "            critic_optim.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            \n",
    "            state = state_prime\n",
    "\n",
    "            # print(f'Actor loss is {actor_loss} and critic loss is {critic_loss}')\n",
    "            if state_prime[0] >= 0.5:\n",
    "                critic_optim.step()\n",
    "                critic_lr_scheduler.step()\n",
    "                break\n",
    "            # print(state)\n",
    "        print(f'This is the count {count_a} for episode {episode}')\n",
    "        count_actions.append(count_a)\n",
    "        total_a += count_a\n",
    "        total_count_actions.append(total_a)\n",
    "        \n",
    "    # torch.save(actor, f'actor{k}.pkl')\n",
    "    # torch.save(critic, f'critic{k}.pkl')\n",
    "    env.close()\n",
    "    count_ca.append(count_actions)\n",
    "    count_tca.append(total_count_actions)\n",
    "\n",
    "\n",
    "avg_ca = np.array(count_ca)\n",
    "avg_ca = np.average(count_ca, axis=0)\n",
    "plt.figure()\n",
    "plt.title('Count of Episodes vs Count of Actions')\n",
    "plt.xlabel('Count of Episodes')\n",
    "plt.ylabel('Count of Actions')\n",
    "plt.plot(count_episode, avg_ca)\n",
    "plt.savefig('mc_count_actions_ac.jpg')\n",
    "plt.show()\n",
    "\n",
    "avg_tca = np.array(count_tca)\n",
    "avg_tca = np.average(count_tca, axis=0)\n",
    "plt.figure()\n",
    "plt.title('Total Actions vs Count of Episodes ')\n",
    "plt.ylabel('Count of Episodes')\n",
    "plt.xlabel('Total Count of Actions')\n",
    "plt.plot(avg_tca, count_episode)\n",
    "plt.savefig('mc_total_actions_ac.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "190a94b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa6fb8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34678385, 0.25450605], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d90bffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31516414, 0.70109362])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scale(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2d2fad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fourier_basis(min_max_scale(state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86e88d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34678385, 0.25450605], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a53be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# env = gym.make('MountainCar-v0')\n",
    "state = env.reset()\n",
    "\n",
    "while not isTerminal:\n",
    "    print(state)\n",
    "    phi_curr = fourier_basis(min_max_scale(state))\n",
    "    state_tensor = torch.from_numpy(phi_curr).float().unsqueeze(0)\n",
    "    v_curr = critic(state_tensor)\n",
    "    #Pick action\n",
    "    action, log_prob = pick_action(actor, state=state_tensor)\n",
    "    state_prime, reward, isTerminal, info = env.step(action.item())\n",
    "    state_prime = torch.FloatTensor(state_prime)\n",
    "    state = state_prime\n",
    "    # env.step(env.action_space.sample())\n",
    "    # env.render('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64bb0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# env = gym.make('MountainCar-v0')\n",
    "state = env.reset()\n",
    "\n",
    "while not isTerminal:\n",
    "    print(state)\n",
    "    phi_curr = fourier_basis(min_max_scale(state))\n",
    "    state_tensor = torch.from_numpy(phi_curr).float().unsqueeze(0)\n",
    "    v_curr = critic(state_tensor)\n",
    "    #Pick action\n",
    "    action, log_prob = pick_action(actor, state=state_tensor)\n",
    "    state_prime, reward, isTerminal, info = env.step(action.item())\n",
    "    state_prime = torch.FloatTensor(state_prime)\n",
    "    state = state_prime\n",
    "    # env.step(env.action_space.sample())\n",
    "    # env.render('human')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa22954",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc09f31dac7c0d375489b816e1f71545b84c713f14d72a59d408a359f22c77a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
